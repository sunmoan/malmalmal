# 주요 도전 요소 및 문제 개요

### (1) 멀티턴 대화의 문맥 이해 필요

- 각 샘플은 여러 발화(turn)로 구성된 대화이며, 문맥적 흐름을 파악해야 함.
- 욕설이나 위협적 단어가 없어도 문맥상 모욕·협박·괴롭힘으로 분류되는 경우 존재.
- 단순 키워드 매칭으로는 불충분하며, **전체 대화 문맥 및 뉘앙스**를 반영해야 함.

### (2) 유사 어휘 간의 맥락적 차이

- **협박 vs 갈취**: 둘 다 위협적 표현을 포함하지만, 갈취는 금전 요구나 공갈이 핵심.
- **직장 내 괴롭힘 vs 기타 괴롭힘**: 공격적 언어 유사하더라도, 회사·업무 맥락 언급 여부로 구분.
- 따라서 문장 단위보다는 **대화 전체를 인코딩**해야 하며, 필요시 발화 순서·역할 정보 활용.

### (3) 일반 대화 데이터 부족

- 학습 데이터에는 일반 대화가 없음.
- 테스트셋에는 일반 대화가 존재하므로, **외부/합성 데이터**로 일반 대화를 보완해야 함.

# 선행 연구

- **네이버 클린봇 AI**: 문맥 기반 악성 댓글 판별의 중요성 강조.
- 과거에는 대화를 문장별 인코딩 후 결합하는 **계층적 구조(Hierarchical Model)** 접근이 주류.
- 최근에는 BERT 등 **Transformer 기반 모델**로 전체 대화를 하나의 시퀀스로 처리하는 방식이 효과적.
- 한국어 데이터에 적합한 사전학습모델 후보:
  - **KLUE-BERT-base**
  - **KoELECTRA-base**

> 출처: [https://arxiv.org/html/2503.14023v2](https://arxiv.org/html/2503.14023v2)

# 모델 선정과 근거

- **BERT 계열**은 양방향 어텐션으로 문맥 파악이 우수.
- 협박·괴롭힘 표현은 다양하고 미묘하므로 **F1-score 중심의 평가**에 유리.
- 대안으로 BERT 구조를 직접 구현하여 비교 가능.
-
- 목적: 문맥적 뉘앙스와 발화 흐름을 포착하는 모델.

# 데이터 전처리 및 증강 전략

### 1. 입력 구조화

- 대화 문자열을 `\n`으로 구분 → 실제 입력에서는 `[SEP]` 토큰으로 변환  
  예시:

- 모델이 문장 경계를 인식하면서 대화 전체 문맥을 이해하도록 구성.

### 2. 화자 구분 처리

- 기본 데이터에는 화자 구분(A/B)이 없음.
- 필요시 스피커 토큰 추가 가능:  
  예: `[A] 발화1 [SEP] [B] 발화2 [SEP] ...`
- 다만 공격성 판별에서는 화자보다는 **내용**이 중요하므로 기본적으로는 생략 가능.

### 3. 텍스트 정제

- 한글 비속어·은어 포함 그대로 유지 (모델이 구어체 학습 경험 있음).
- “니가” → “네가” 등 최소한의 정규화만 수행.
- 의미 없는 이모티콘·특수문자·메타정보는 제거.

### 4. 일반 대화 합성

- 공격성 없는 **일상적 구어체 데이터**를 확충.
- 다양한 주제(일상, 업무, 취미 등) 포함.
- “공격성 표현이 절대 포함되지 않음”을 보장.

---

**결론:**  
문맥 중심의 분류를 위해 `대화 전체 → [SEP] 기반 시퀀스 입력 → 사전학습(직접구현 하는 방법) BERT 인코더` 구성이 좋을 것 같음.  
일반 대화의 부족은 **외부·합성 데이터 보강**으로 보완.
